{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly Download from GC and save as netcdf files\n",
    "- This is for those who cannot use zarr/python for processing the CMIP6 datasets\n",
    "- Please note that the netcdf files have CF-compliant time grids, but might not be what you are used to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gcsfs #google cloud file system. \n",
    "import xarray as xr\n",
    "import warnings\n",
    "from glob import glob # use * !\n",
    "import scipy.io as sio\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import search_df, add_time_info, get_zdict #extra functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_area_and_seasonal_mean(danom, xlim, ylim, slim, mask=1):\n",
    "    \"\"\"\n",
    "    Weights each grid point by the cos(latitude), computes area mean, normalizing by areaa mean of the weights\n",
    "    returns:\n",
    "        DataArray:  global mean for each model\n",
    "    \"\"\"  \n",
    "    xlim = np.array(xlim)\n",
    "    xlim += (xlim<0 )*360\n",
    "    if xlim[0]>xlim[1]:\n",
    "        lon_sel = (danom.lon>xlim[0])+(danom.lon<xlim[1])\n",
    "    else:\n",
    "        lon_sel = (danom.lon>xlim[0])*danom.lon<xlim[1]\n",
    "    \n",
    "    if type(mask)!=int:\n",
    "        mask = (xr.ones_like(danom)*mask).isel({'lat': (danom.lat>ylim[0])*(danom.lat<ylim[1]), 'lon': lon_sel})\n",
    "    \n",
    "    danom = danom.isel({'lat': (danom.lat>ylim[0])*(danom.lat<ylim[1]), 'lon': lon_sel, 'time': (danom['time'].dt.month >= slim[0])*(danom['time'].dt.month <= slim[1])})\n",
    "    coslat = np.cos(np.deg2rad(danom.lat))\n",
    "    weights = xr.ones_like(danom)*coslat*mask\n",
    "    weight_mean = weights.mean(['lat','lon'], keep_attrs=True)\n",
    "    area_mean = (danom * weights).mean(['lat','lon'], keep_attrs=True)/weight_mean\n",
    "    if area_mean.time.dtype!='datetime64[ns]':\n",
    "        area_mean['time'] = area_mean.indexes['time'].year\n",
    "        return area_mean.groupby('time').mean(dim='time', keep_attrs=True)\n",
    "        #area_mean.indexes['time'].to_datetimeindex()\n",
    "        #there are lots of dftime.DatetimeNoLeap. this would matter a touch if I used a weighted average.\n",
    "    else:   \n",
    "        #month_length = danom.time.dt.days_in_month\n",
    "        #this actually isn't right! Let's just do an unweighted mean for now :(\n",
    "        #weights = month_length/sum(month_length[slim[0]:slim[1]+1])\n",
    "        #Sm = (weights*area_mean)\n",
    "        #return Sm.groupby(grp).sum(dim='time', keep_attrs=True)\n",
    "        return area_mean.groupby(area_mean.time.dt.year).mean(dim='time', keep_attrs=True)\n",
    "    \n",
    "    #technically this is inconsistent handling; one makes a dimension called \"time\" and the other makes \"years\". I have to deal with that in my matlab code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to write local netcdf files:\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "mach = os.uname()[1]\n",
    "\n",
    "zarr_local = f'/home/{username}/netcdf/cmip6/preprocessed'\n",
    "if not os.path.exists(zarr_local):\n",
    "    print(f'Please create the directory {zarr_local}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "      <th>version</th>\n",
       "      <th>status</th>\n",
       "      <th>severity</th>\n",
       "      <th>issue_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>AS-RCEC</td>\n",
       "      <td>TaiESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>od550aer</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/AS-RCEC/TaiESM1/histSST/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200310</td>\n",
       "      <td>good</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmrbc</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190718</td>\n",
       "      <td>good</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmrdust</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20191127</td>\n",
       "      <td>good</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmroa</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20190809</td>\n",
       "      <td>good</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>histSST</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>AERmon</td>\n",
       "      <td>mmrso4</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20191127</td>\n",
       "      <td>good</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  activity_id institution_id source_id experiment_id member_id table_id  \\\n",
       "0  AerChemMIP        AS-RCEC   TaiESM1       histSST  r1i1p1f1   AERmon   \n",
       "1  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "2  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "3  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "4  AerChemMIP            BCC  BCC-ESM1       histSST  r1i1p1f1   AERmon   \n",
       "\n",
       "  variable_id grid_label                                             zstore  \\\n",
       "0    od550aer         gn  gs://cmip6/AerChemMIP/AS-RCEC/TaiESM1/histSST/...   \n",
       "1       mmrbc         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "2     mmrdust         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "3       mmroa         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "4      mmrso4         gn  gs://cmip6/AerChemMIP/BCC/BCC-ESM1/histSST/r1i...   \n",
       "\n",
       "  dcpp_init_year   version status severity issue_url  \n",
       "0            NaN  20200310   good     none      none  \n",
       "1            NaN  20190718   good     none      none  \n",
       "2            NaN  20191127   good     none      none  \n",
       "3            NaN  20190809   good     none      none  \n",
       "4            NaN  20191127   good     none      none  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the master CMIP6 Google Cloud catalog\n",
    "df_cloud = pd.read_csv('https://cmip6.storage.googleapis.com/cmip6-zarr-consolidated-stores-noQC.csv', dtype='unicode')\n",
    "df_cloud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose basic configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we search the CMIP6 data for the datasets you need - using the same keywords as at the ESGF sites\n",
    "#       https://esgf-node.llnl.gov/search/cmip6/\n",
    "\n",
    "debug = False\n",
    "\n",
    "# must choose ONE table_id  (only works for *mon or *day)\n",
    "table_id = 'Amon'\n",
    "\n",
    "#must choose LIST of experiments, variables\n",
    "experiments = ['hist-aer']#, 'historical', 'hist-nat', 'hist-GHG', 'piControl' 'amip-hist',\n",
    "variables = ['pr','ts']\n",
    "\n",
    "# can specify 'All' or give a list or string\n",
    "sources = ['CESM2']# 'GFDL-ESM4'['CanESM5-CanOE']#CMCC-CM2-SR5']#'CIESM']#MCM-UA-1-0']  #AWI-CM-1-1-MR']#SAM0-UNICON']# omit the [] to get all models with CESM2 in their name\n",
    "#sources = 'All'\n",
    "members = ['r3i1p1f1']\n",
    "#members = 'All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of matching datasets 1\n"
     ]
    }
   ],
   "source": [
    "search = {'table_id':table_id}\n",
    "search['experiment_id'] = experiments\n",
    "search['variable_id'] = variables\n",
    "if sources != 'All':\n",
    "    search['source_id'] = sources\n",
    "if members != 'All':\n",
    "    search['member_id'] = members\n",
    "    \n",
    "df_available = search_df(df_cloud, **search)\n",
    "\n",
    "print('number of matching datasets',len(df_available))\n",
    "\n",
    "#523 historical simulations < 536 on the cite directly. Do I want to figure out which simulations are missing? \n",
    "# Or do I trust that they are missing for a reason?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>zstore</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "      <th>version</th>\n",
       "      <th>status</th>\n",
       "      <th>severity</th>\n",
       "      <th>issue_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110253</th>\n",
       "      <td>DAMIP</td>\n",
       "      <td>NCAR</td>\n",
       "      <td>CESM2</td>\n",
       "      <td>hist-aer</td>\n",
       "      <td>r3i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>pr</td>\n",
       "      <td>gn</td>\n",
       "      <td>gs://cmip6/DAMIP/NCAR/CESM2/hist-aer/r3i1p1f1/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20200305</td>\n",
       "      <td>good</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       activity_id institution_id source_id experiment_id member_id table_id  \\\n",
       "110253       DAMIP           NCAR     CESM2      hist-aer  r3i1p1f1     Amon   \n",
       "\n",
       "       variable_id grid_label  \\\n",
       "110253          pr         gn   \n",
       "\n",
       "                                                   zstore dcpp_init_year  \\\n",
       "110253  gs://cmip6/DAMIP/NCAR/CESM2/hist-aer/r3i1p1f1/...            NaN   \n",
       "\n",
       "         version status severity issue_url  \n",
       "110253  20200305   good     none      none  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of mask datasets 1\n"
     ]
    }
   ],
   "source": [
    "#only use the MASK code for TS!\n",
    "\n",
    "search_mask = {'table_id':'fx'}\n",
    "search_mask['experiment_id'] = ['historical', 'piControl', '1pctCO2','hist-resIPO','hist-1950HC']\n",
    "search_mask['variable_id'] = ['sftlf']\n",
    "if sources != 'All':\n",
    "    search_mask['source_id'] = sources\n",
    "if members != 'All':\n",
    "    search_mask['member_id'] = members\n",
    "historical_mask = search_df(df_cloud, **search_mask)\n",
    "\n",
    "print('number of mask datasets',len(historical_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For proper debugging, it is helpful to add time grid information to dataframe:\n",
    "if debug:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        dfa = add_time_info(df_available)\n",
    "else:\n",
    "    dfa = df_available.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gs://cmip6/CMIP/NCC/NorESM2-LM/historical/r2i1p1f1/Amon/ts/gn/'],\n",
       "      dtype='<U62')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only use MASK code for TS!\n",
    "\n",
    "def get_ids(dfa, id_name):\n",
    "    zdicts = list(map(get_zdict, list(dfa.zstore.values)))\n",
    "    return set(map(lambda x: x[id_name], zdicts))\n",
    "\n",
    "id_name = 'source_id'\n",
    "historical_mask_models = get_ids(historical_mask, id_name)\n",
    "sst_models = get_ids(dfa, id_name)\n",
    "\n",
    "maskable_models = sst_models.intersection(historical_mask_models)\n",
    "\n",
    "gsurls = np.array([gsurl for gsurl in dfa.zstore.values if get_zdict(gsurl)['source_id'] in maskable_models])\n",
    "missing = np.array([gsurl for gsurl in dfa.zstore.values if not get_zdict(gsurl)['source_id'] in maskable_models])\n",
    "\n",
    "masks = historical_mask.groupby('source_id').first()\n",
    "\n",
    "gsurls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pr:\n",
    "gsurls = np.array(dfa.zstore.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "    dm = dfa[['experiment_id','source_id','member_id','variable_id','start','stop']].groupby([\n",
    "             'experiment_id','start','stop','source_id']).nunique()[['member_id']]\n",
    "\n",
    "    table = pd.DataFrame.pivot_table(dm,\n",
    "                                     values='member_id',\n",
    "                                     index=['source_id','start','stop'],\n",
    "                                     columns=['experiment_id'],\n",
    "                                     aggfunc=np.sum,\n",
    "                                     fill_value=0)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://errata.es-doc.org/static/view.html?uid=5ebabff0-388f-07bc-b2cf-d44dcbb2940f'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.issue_url.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(token='anon', access='read_only') #the actual files, not the list of files woohoo FILE SYSTEM\n",
    "#fs.get_mapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving file /home/rebecca/netcdf/cmip6/preprocessed/historical/ts_NCC_NorESM2-LM_r1i1p1f1.nc\n"
     ]
    }
   ],
   "source": [
    "#gsurls = dfa.zstore.values #zstore is the url where the data is stored\n",
    "\n",
    "ds_list = []\n",
    "ds_failed_list = []\n",
    "\n",
    "def update_vars(ds):\n",
    "    for var in [var for var in ds.coords]:\n",
    "        if 'bounds' in var:\n",
    "            nvar = var.replace('bounds','bnds')\n",
    "            #print(var,nvar)\n",
    "            ds = ds.rename({var:nvar})\n",
    "        if 'latitude' in var:\n",
    "            nvar = var.replace('latitude','lat')\n",
    "            #print(var,nvar)\n",
    "            ds = ds.rename({var:nvar})\n",
    "        if 'longitude' in var:\n",
    "            nvar = var.replace('longitude','lon')\n",
    "            #print(var,nvar)\n",
    "            ds = ds.rename({var:nvar})\n",
    "    return ds        \n",
    "    \n",
    "    \n",
    "for gsurl in gsurls:\n",
    "    zdict = get_zdict(gsurl) #naomi func for metadata\n",
    "    institution = zdict['institution_id']\n",
    "    model = zdict['source_id']\n",
    "    run = zdict['member_id']\n",
    "    variable = zdict['variable_id']\n",
    "    expt = zdict['experiment_id']\n",
    "    filename = f'{variable}_{institution}_{model}_{run}'\n",
    "    ncdir = f'{zarr_local}/{expt}'\n",
    "    ncfile = f'{ncdir}/{filename}.nc'\n",
    "    \n",
    "    ncfiles = glob(ncfile) #check not to double-download files\n",
    "    if len(ncfiles) > 0:\n",
    "        print(ncfiles, 'already exists')\n",
    "        continue\n",
    "        \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        ds = xr.open_zarr(fs.get_mapper(gsurl),consolidated=True) #gets info about the file. get_mapper! always use consolidated=True\n",
    "        if variable=='ts':\n",
    "            mask_ds = xr.open_zarr(fs.get_mapper(masks['zstore'][model]),consolidated=True) \n",
    "        \n",
    "    #month_length = ds.time.dt.days_in_month #for some reason the first one doesn't have this...\n",
    "        \n",
    "    ds = update_vars(ds)\n",
    "    if variable=='ts':\n",
    "        mask_ds = update_vars(mask_ds)\n",
    "        ls_mask = np.floor(1-mask_ds.sftlf.values/100)\n",
    "    \n",
    "    try:\n",
    "        if variable=='ts':\n",
    "            NA = compute_area_and_seasonal_mean(ds, [-75,-15], [10,40], [7,9])\n",
    "            GT = compute_area_and_seasonal_mean(ds, [0,360],[-20,20],[7,9], mask=ls_mask)\n",
    "            Sm = NA\n",
    "            Sm = Sm.rename_vars({'ts':'NA'})\n",
    "            Sm['GT'] = GT.ts\n",
    "            Sm['NARI'] = NA.ts - GT.ts\n",
    "        else:\n",
    "            Sm = compute_area_and_seasonal_mean(ds, [-20,40], [12,18], [7,9])\n",
    "  \n",
    "    except ValueError:\n",
    "        print(f'value error for {ncfile}')\n",
    "        ds_failed_list += [ds]\n",
    "        continue\n",
    "        \n",
    "    #have to customize this to the variable I'm using!\n",
    "    if variable=='ts':\n",
    "        if not ds.ts.attrs['units']=='K':\n",
    "            print(\"cannot comprehend units ({}), skipping model {}\".format(ds.ts.attrs['units'], model))\n",
    "            continue\n",
    "    elif variable=='pr':\n",
    "        if ds.pr.attrs['units'] == 'kg m-2 s-1':\n",
    "            Sm *= 86400\n",
    "        else:\n",
    "            print(\"cannot comprehend units ({}), skipping model {}\".format(ds.pr.attrs['units'], model))\n",
    "            continue\n",
    "    else:\n",
    "        print(\"need to make new units case for variable {}\".format(variable))\n",
    "\n",
    "    os.system(f'mkdir -p {ncdir}')\n",
    "    try:\n",
    "        Sm.to_netcdf(ncfile,mode='w',unlimited_dims=['time','year'])  #saves the file. Don't have to do this before I'm ready! But ds is replaced each time...\n",
    "        ds_list += [Sm]\n",
    "        print(f'saving file {ncfile}')\n",
    "    except ValueError:\n",
    "        print(f'value error for {ncfile}')\n",
    "        ds_failed_list += [Sm]\n",
    "        continue    \n",
    "        \n",
    "    #ok I got an error for a model which uses i/j coordinates instead of lat lon! OY VEY...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (time: 165)\n",
       "Coordinates:\n",
       "  * time     (time) int64 1850 1851 1852 1853 1854 ... 2010 2011 2012 2013 2014\n",
       "Data variables:\n",
       "    NA       (time) float64 dask.array<chunksize=(1,), meta=np.ndarray>\n",
       "    GT       (time) float64 dask.array<chunksize=(1,), meta=np.ndarray>\n",
       "    NARI     (time) float64 dask.array<chunksize=(1,), meta=np.ndarray>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.concat(ds_list, dim='dataset') #this isn't working bc different variables. Exist other ways to combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regridding: xesmf (earth system modelling federation). works for lat-lon, but not time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(ds2.sftlf, ds1.sftlf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "\n",
    "ds.ts[0].plot()\n",
    "(ds*xr.ones_like(ds)*np.cos(np.deg2rad(ds.lat))*ls_mask).ts[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tree -L 9 ~/CMIP6-downloads #unix tree of created files; I didn't create any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! du -sh ~/CMIP6-downloads/*/*/*/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/home/naomi/CMIP6-downloads/CMIP/NCAR/CESM2/historical/r1i1p1f1/Amon/sfcWind/gn/sfcWind.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sfcWind.plot(vmin=0,vmax=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert longitude coordinates from 0-359 to -180-179:\n",
    "\n",
    "ds2 = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180)).sortby('lon')\n",
    "\n",
    "#or\n",
    "\n",
    "ds.coords['lon'] = (ds.coords['lon'] + 180) % 360 - 180\n",
    "ds = ds.sortby(ds.lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.sfcWind[0].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myPython3.6",
   "language": "python",
   "name": "my3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
